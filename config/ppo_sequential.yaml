# PPO Sequential Training Configuration (CPU-Optimized)

# Environment settings
env:
  name: "procgen-coinrun-v0"  # Procgen environment name
  num_envs: 32  # Number of parallel environments (optimized for CPU)
  seed: 42  # Random seed (null for random)

# Training hyperparameters
training:
  total_timesteps: 25000000  # Total training timesteps
  n_steps: 128  # Steps per rollout (reduced for CPU efficiency)
  batch_size: 1024  # Batch size for training (optimized for CPU memory)
  n_epochs: 4  # Number of epochs per update
  
# PPO hyperparameters
ppo:
  learning_rate: 0.0005  # Learning rate (5e-4)
  gamma: 0.999  # Discount factor
  gae_lambda: 0.95  # GAE lambda
  clip_range: 0.2  # PPO clipping parameter
  clip_range_vf: null  # Value function clipping (null for no clipping)
  normalize_advantage: true  # Normalize advantages
  ent_coef: 0.01  # Entropy coefficient
  vf_coef: 0.5  # Value function coefficient
  max_grad_norm: 0.5  # Maximum gradient norm

# Model architecture
model:
  hidden_size: 512  # Hidden layer size

# Logging and checkpointing
logging:
  log_interval: 1  # Log every N updates
  save_interval: 100  # Save checkpoint every N updates
  eval_episodes: 10  # Number of episodes for evaluation
  checkpoint_dir: "./checkpoints/ppo_sequential"
  log_dir: "./logs"

# Hardware (CPU-focused)
hardware:
  device: "cpu"  # cpu (default) or cuda
  num_threads: null  # Number of CPU threads (null for auto-detect)

